{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy and matplot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import keras \n",
    "import keras as kr \n",
    "# this are need for export the model al proto for be used in c#\n",
    "from keras import backend as K\n",
    "import tensorflow.compat.v1 as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image generator for argumented data\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility for split the data\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Images \n",
    "x = []\n",
    "with open(\"data/images.txt\") as f:\n",
    "    for line in f:\n",
    "      x.append(np.asarray([float(x) for x in line.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8298"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of images\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert into np and reshape\n",
    "x = np.asarray(x)\n",
    "x = x.reshape(len(x),30,30,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to float32\n",
    "x = x.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16d06dcb348>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAANLUlEQVR4nO3dXYxc9XnH8e9TY8u8GGHX6xfMwjrGQIsRpqxQEVUFRIkwCgIuQOECuRKquQhSLOWiiF6ECy5QCUS5qJBMseJUlCQSIHxh2gBCQrlBLMY1ONs2vLiJg2UvImAwQsbm6cUeoq3Zc3aZtzPw/36k0cyc57w8HPzbM2f+c2YiM5H09fdnbTcgaTAMu1QIwy4VwrBLhTDsUiEMu1SIU7pZOCKuA34CLAD+JTPvb5p/+fLlOTY21s0mJTXYv38/7777bsxW6zjsEbEA+GfgW8AB4OWI2JmZv6lbZmxsjImJiU43KWkO4+PjtbVuXsZfAbyRmW9l5jHg58CNXaxPUh91E/Y1wO9nPD9QTZM0hLoJ+2znBV/47G1EbImIiYiYmJqa6mJzkrrRTdgPAKMznp8DvHPyTJm5LTPHM3N8ZGSki81J6kY3YX8ZWB8RayNiEfBdYGdv2pLUax2/G5+ZxyPiLuA/mB56256Z+3rWmaSe6mqcPTN3Abt61IukPvITdFIhDLtUCMMuFcKwS4Uw7FIhDLtUCMMuFcKwS4Uw7FIhDLtUCMMuFcKwS4Uw7FIhDLtUCMMuFcKwS4Uw7FIhDLtUCMMuFcKwS4Uw7FIhDLtUCMMuFcKwS4Uw7FIhDLtUCMMuFaKr33qLiP3Ah8AJ4HhmjveiKUm911XYK9dk5rs9WI+kPvJlvFSIbsOewK8i4pWI2NKLhiT1R7cv46/KzHciYgXwbET8V2a+OHOG6o/AFoBzzz23y81J6lRXR/bMfKe6Pww8BVwxyzzbMnM8M8dHRka62ZykLnQc9og4PSKWfP4Y+Dbweq8ak9Rb3byMXwk8FRGfr+ffMvPfe9KVpJ7rOOyZ+RZwaQ97kdRHDr1JhTDsUiEMu1QIwy4VwrBLhTDsUiEMu1QIwy4VwrBLhTDsUiEMu1QIwy4VwrBLhTDsUiEMu1QIwy4VwrBLhTDsUiEMu1QIwy4Vohe/9SbN6pZbbqmtHT16tLa2a9eufrRTPI/sUiEMu1QIwy4VwrBLhTDsUiEMu1QIwy4VYs5x9ojYDnwHOJyZG6ppy4BfAGPAfuDWzPxj/9osx6mnnlpbW7VqVW3t7bff7kc7jW6//fbGelNPF198ca/b0Rzmc2T/KXDdSdPuBp7PzPXA89VzSUNszrBn5ovAeydNvhHYUT3eAdzU474k9Vin5+wrM/MgQHW/om7GiNgSERMRMTE1NdXh5iR1q+9v0GXmtswcz8zxkZGRfm9OUo1Ow34oIlYDVPeHe9eSpH7oNOw7gc3V483A071pR1K/zGfo7XHgamB5RBwAfgjcD/wyIu4AfgfUX8uoL+X48eO1tZUrVw6wk7lNTk421kdHR2trw/bfUoI5w56Zt9WUvtnjXiT1kZ+gkwph2KVCGHapEIZdKoRhlwrht8sOmXPOOae2tnDhwtrapk2bamvPPPNMx/00rXfJkiWNy65fv762tm7duo57Umc8skuFMOxSIQy7VAjDLhXCsEuFMOxSIRx6GzJNV4NlZm3tlFPq/1eef/75jdtcvHhxbW3t2rW1taVLlzaud+vWrbW1s88+u3FZ9Z5HdqkQhl0qhGGXCmHYpUIYdqkQhl0qhGGXCuE4+5Bpuoy1yXPPPdfxNpsuN23qZ2xsrHG9H3zwQW3NcfbB88guFcKwS4Uw7FIhDLtUCMMuFcKwS4WYzw87bge+AxzOzA3VtHuBvwemqtnuycxd/WqyJE1DUocP1/8y9qJFi2prR44cadzmihUramtN3yDbdFntXMs2eeCBB2pr5513XuOyy5cvr61de+21HfXzdTGfI/tPgetmmf7jzNxY3Qy6NOTmDHtmvgi8N4BeJPVRN+fsd0XE3ojYHhHNX1kiqXWdhv1hYB2wETgIPFg3Y0RsiYiJiJiYmpqqm01Sn3UU9sw8lJknMvMz4BHgioZ5t2XmeGaOj4yMdNqnpC51FPaIWD3j6c3A671pR1K/zGfo7XHgamB5RBwAfghcHREbgQT2A3f2sceiXHLJJbW13bt319YuuOCCjpYDOOuss2prCxYsqK199NFHjes9evRobe3VV1+trY2OjtbWmobWANasWdNYL9mcYc/M22aZ/GgfepHUR36CTiqEYZcKYdilQhh2qRCGXSqEYZcK4bfLDpmmTxlec801tbUXXnihtrZq1arGbTZ9g+yJEydqa++//37jeu+7777a2qZNm2pry5Ytq629+eabjdss/TLWJh7ZpUIYdqkQhl0qhGGXCmHYpUIYdqkQDr0NmTvvrL9auOnHG/ft29fxNo8dO1Zb++STT2prTZe/Atxwww21tabLWK+88srG9aozHtmlQhh2qRCGXSqEYZcKYdilQhh2qRAOvX2FbNiwobbWNPQ219Vpn376aW2t6Sq8yy+/vHG9H3/8cW3N4bXB88guFcKwS4Uw7FIhDLtUCMMuFcKwS4WYzw87jgI/A1YBnwHbMvMnEbEM+AUwxvSPO96amX/sX6tqsnbt2tpa0xAYNP8Y4qWXXlpbO/PMM+duTENjPkf248APMvMvgL8GvhcRfwncDTyfmeuB56vnkobUnGHPzIOZubt6/CEwCawBbgR2VLPtAG7qV5OSuvelztkjYgy4DHgJWJmZB2H6DwKwotfNSeqdeYc9Is4AngC2ZuaRL7HcloiYiIiJqampTnqU1APzCntELGQ66I9l5pPV5EMRsbqqrwYOz7ZsZm7LzPHMHG/6nLWk/poz7BERwKPAZGY+NKO0E9hcPd4MPN379iT1ynyuersKuB14LSL2VNPuAe4HfhkRdwC/A27pT4uSemHOsGfmr4GoKX+zt+2oyaJFi2prTT+GuHLlysb1XnjhhbW1U07xKuivCz9BJxXCsEuFMOxSIQy7VAjDLhXCsEuFcFzlK2Tx4sW1tYsuuqi2dtppp3W8zW6W1XDxyC4VwrBLhTDsUiEMu1QIwy4VwrBLhXDo7WvC4TXNxSO7VAjDLhXCsEuFMOxSIQy7VAjDLhXCobevEIfI1A2P7FIhDLtUCMMuFcKwS4Uw7FIhDLtUiPn8iutoRLwQEZMRsS8ivl9Nvzci/hARe6rb9f1vV1Kn5jPOfhz4QWbujoglwCsR8WxV+3Fm/qh/7Unqlfn8iutB4GD1+MOImATW9LsxSb31pc7ZI2IMuAx4qZp0V0TsjYjtEbG0x71J6qF5hz0izgCeALZm5hHgYWAdsJHpI/+DNcttiYiJiJiYmprqQcuSOjGvsEfEQqaD/lhmPgmQmYcy80RmfgY8Alwx27KZuS0zxzNzfGRkpFd9S/qS5vNufACPApOZ+dCM6atnzHYz8Hrv25PUK/N5N/4q4HbgtYjYU027B7gtIjYCCewH7uxLh5J6Yj7vxv8aiFlKu3rfjqR+8RN0UiEMu1QIwy4VwrBLhTDsUiEMu1QIwy4VwrBLhTDsUiEMu1QIwy4VwrBLhTDsUiEMu1QIwy4VwrBLhTDsUiEMu1QIwy4VwrBLhTDsUiEMu1QIwy4VwrBLhTDsUiEMu1QIwy4VwrBLhYjMHNzGIqaA/50xaTnw7sAamJv9NBu2fmD4emq7n/Myc2S2wkDD/oWNR0xk5nhrDZzEfpoNWz8wfD0NWz8z+TJeKoRhlwrRdti3tbz9k9lPs2HrB4avp2Hr509aPWeXNDhtH9klDUgrYY+I6yLivyPijYi4u40eTupnf0S8FhF7ImKipR62R8ThiHh9xrRlEfFsRPy2ul/acj/3RsQfqv20JyKuH2A/oxHxQkRMRsS+iPh+Nb2VfdTQT2v7aC4DfxkfEQuA/wG+BRwAXgZuy8zfDLSR/9/TfmA8M1sbH42IvwU+An6WmRuqaf8EvJeZ91d/FJdm5j+02M+9wEeZ+aNB9HBSP6uB1Zm5OyKWAK8ANwF/Rwv7qKGfW2lpH82ljSP7FcAbmflWZh4Dfg7c2EIfQyUzXwTeO2nyjcCO6vEOpv8xtdlPazLzYGburh5/CEwCa2hpHzX0M7TaCPsa4Pcznh+g/Z2UwK8i4pWI2NJyLzOtzMyDMP2PC1jRcj8Ad0XE3upl/sBOK2aKiDHgMuAlhmAfndQPDME+mk0bYY9ZprU9JHBVZv4VsAn4XvUSVl/0MLAO2AgcBB4cdAMRcQbwBLA1M48Mevvz6Kf1fVSnjbAfAEZnPD8HeKeFPv4kM9+p7g8DTzF9qjEMDlXnhp+fIx5us5nMPJSZJzLzM+ARBryfImIh08F6LDOfrCa3to9m66ftfdSkjbC/DKyPiLURsQj4LrCzhT4AiIjTqzdYiIjTgW8DrzcvNTA7gc3V483A0y328nmYPnczA9xPERHAo8BkZj40o9TKPqrrp819NKfMHPgNuJ7pd+TfBP6xjR5m9PIN4D+r2762+gEeZ/pl36dMv/q5A/hz4Hngt9X9spb7+VfgNWAv0yFbPcB+/obp0729wJ7qdn1b+6ihn9b20Vw3P0EnFcJP0EmFMOxSIQy7VAjDLhXCsEuFMOxSIQy7VAjDLhXi/wCKFMpqdoyD2wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check one image\n",
    "plt.imshow(x[2250].reshape(30,30), cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load labels\n",
    "y = []\n",
    "with open(\"data/labels.txt\") as f:\n",
    "    for line in f:\n",
    "      y.append(int(line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfor labels into np array\n",
    "y = np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split labels into vectors of size 10\n",
    "y = kr.utils.to_categorical(y, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into test and train\n",
    "# 33% would be the test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\pepe\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "\n",
    "model = kr.models.Sequential()\n",
    "model.add(kr.layers.Conv2D(32,kernel_size=(3, 3),activation='relu',input_shape=(30,30,1)))\n",
    "kr.layers.BatchNormalization(axis=-1)\n",
    "model.add(kr.layers.Conv2D(32,kernel_size=(3, 3),activation='relu'))\n",
    "model.add(kr.layers.MaxPooling2D(pool_size=(2, 2),))\n",
    "\n",
    "kr.layers.BatchNormalization(axis=-1)\n",
    "model.add(kr.layers.Conv2D(64,kernel_size=(3, 3),activation='relu'))\n",
    "kr.layers.BatchNormalization(axis=-1)\n",
    "model.add(kr.layers.Conv2D(64,kernel_size=(3, 3),activation='relu'))\n",
    "model.add(kr.layers.MaxPooling2D(pool_size=(2, 2),))\n",
    "\n",
    "model.add(kr.layers.Flatten())\n",
    "model.add(kr.layers.Dense(units=456, activation='relu'))\n",
    "kr.layers.BatchNormalization()\n",
    "model.add(kr.layers.Dropout(0.1))\n",
    "model.add(kr.layers.Dense(units=13, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile model\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 9, 9, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 456)               467400    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 456)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 13)                5941      \n",
      "=================================================================\n",
      "Total params: 538,333\n",
      "Trainable params: 538,333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# need first and last layer name for use in c#\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create image generator\n",
    "gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
    "                         height_shift_range=0.08, zoom_range=0.08)\n",
    "test_gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#epoch = 10\n",
    "#history_callback = model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=epoch, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_generator = gen.flow(X_train, y_train, batch_size=64)\n",
    "test_generator = test_gen.flow(X_test, y_test, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\pepe\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "937/937 [==============================] - 12s 13ms/step - loss: 0.3300 - accuracy: 0.8926 - val_loss: 0.0201 - val_accuracy: 0.9963\n",
      "Epoch 2/10\n",
      "937/937 [==============================] - 10s 11ms/step - loss: 0.0234 - accuracy: 0.9924 - val_loss: 7.8921e-04 - val_accuracy: 0.9956\n",
      "Epoch 3/10\n",
      "937/937 [==============================] - 10s 11ms/step - loss: 0.0134 - accuracy: 0.9960 - val_loss: 1.9528e-04 - val_accuracy: 0.9998\n",
      "Epoch 4/10\n",
      "937/937 [==============================] - 10s 10ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 2.9962e-05 - val_accuracy: 0.9995\n",
      "Epoch 5/10\n",
      "937/937 [==============================] - 10s 11ms/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 1.5589e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "937/937 [==============================] - 10s 11ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 1.3936e-04 - val_accuracy: 0.9996\n",
      "Epoch 7/10\n",
      "937/937 [==============================] - 10s 11ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 4.0124e-06 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "937/937 [==============================] - 10s 11ms/step - loss: 0.0085 - accuracy: 0.9975 - val_loss: 1.2105e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "937/937 [==============================] - 10s 11ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 2.1371e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "937/937 [==============================] - 10s 11ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 1.2693e-05 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x295b237fc48>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train 10 epoch\n",
    "epoch =10\n",
    "model.fit_generator(train_generator, steps_per_epoch=60000//64, epochs=epoch, \n",
    "                    validation_data=test_generator, validation_steps=10000//64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "937/937 [==============================] - 11s 12ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 1.3132e-07 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "937/937 [==============================] - 10s 11ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 5.5507e-07 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "937/937 [==============================] - 11s 11ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 1.5646e-07 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "937/937 [==============================] - 10s 11ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 7.8952e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "937/937 [==============================] - 11s 11ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 1.3877e-07 - val_accuracy: 0.9985\n",
      "Epoch 6/10\n",
      "937/937 [==============================] - 11s 11ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 2.4680e-07 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "937/937 [==============================] - 10s 11ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "937/937 [==============================] - 11s 11ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 5.4971e-06 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "937/937 [==============================] - 11s 11ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 8.4240e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "937/937 [==============================] - 10s 11ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 2.2483e-06 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x247c1434808>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, steps_per_epoch=60000//64, epochs=epoch, \n",
    "                    validation_data=test_generator, validation_steps=10000//64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze function from stack overflow\n",
    "def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n",
    "    \"\"\"\n",
    "    Freezes the state of a session into a pruned computation graph.\n",
    "\n",
    "    Creates a new computation graph where variable nodes are replaced by\n",
    "    constants taking their current value in the session. The new graph will be\n",
    "    pruned so subgraphs that are not necessary to compute the requested\n",
    "    outputs are removed.\n",
    "    @param session The TensorFlow session to be frozen.\n",
    "    @param keep_var_names A list of variable names that should not be frozen,\n",
    "                          or None to freeze all the variables in the graph.\n",
    "    @param output_names Names of the relevant graph outputs.\n",
    "    @param clear_devices Remove the device directives from the graph for better portability.\n",
    "    @return The frozen graph definition.\n",
    "    \"\"\"\n",
    "    graph = session.graph\n",
    "    with graph.as_default():\n",
    "        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n",
    "        output_names = output_names or []\n",
    "        output_names += [v.op.name for v in tf.global_variables()]\n",
    "        input_graph_def = graph.as_graph_def()\n",
    "        if clear_devices:\n",
    "            for node in input_graph_def.node:\n",
    "                node.device = \"\"\n",
    "        frozen_graph = tf.graph_util.convert_variables_to_constants(\n",
    "            session, input_graph_def, output_names, freeze_var_names)\n",
    "        return frozen_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-20-af0a42548ffb>:27: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.convert_variables_to_constants\n",
      "WARNING:tensorflow:From C:\\Users\\pepe\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\graph_util_impl.py:245: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.extract_sub_graph\n",
      "INFO:tensorflow:Froze 55 variables.\n",
      "INFO:tensorflow:Converted 55 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "# froze the graph\n",
    "frozen_graph = freeze_session(K.get_session(),\n",
    "                              output_names=[out.op.name for out in model.outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../model/gesture_model1.pb'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save model in file\n",
    "tf.train.write_graph(frozen_graph, \"../model/\", \"gesture_model1.pb\", as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1,y1 = train_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16d08f16cc8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "plt.imshow(x1[11].reshape(30,30), cmap='gray')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
