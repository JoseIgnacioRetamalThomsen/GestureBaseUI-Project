{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy and matplot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import keras \n",
    "import keras as kr \n",
    "# this are need for export the model al proto for be used in c#\n",
    "from keras import backend as K\n",
    "import tensorflow.compat.v1 as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image generator for argumented data\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility for split the data\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Images \n",
    "x = []\n",
    "with open(\"data/images.txt\") as f:\n",
    "    for line in f:\n",
    "      x.append(np.asarray([float(x) for x in line.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of images\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert into np and reshape\n",
    "x = np.asarray(x)\n",
    "x = x.reshape(len(x),30,30,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to float32\n",
    "x = x.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a9d4b052c8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check one image\n",
    "plt.imshow(x[2008].reshape(30,30), cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load labels\n",
    "y = []\n",
    "with open(\"data/labels.txt\") as f:\n",
    "    for line in f:\n",
    "      y.append(int(line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfor labels into np array\n",
    "y = np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split labels into vectors of size 10\n",
    "y = kr.utils.to_categorical(y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into test and train\n",
    "# 33% would be the test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\pepe\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "\n",
    "model = kr.models.Sequential()\n",
    "model.add(kr.layers.Conv2D(32,kernel_size=(3, 3),activation='relu',input_shape=(30,30,1)))\n",
    "kr.layers.BatchNormalization(axis=-1)\n",
    "model.add(kr.layers.Conv2D(32,kernel_size=(3, 3),activation='relu'))\n",
    "model.add(kr.layers.MaxPooling2D(pool_size=(2, 2),))\n",
    "\n",
    "kr.layers.BatchNormalization(axis=-1)\n",
    "model.add(kr.layers.Conv2D(64,kernel_size=(3, 3),activation='relu'))\n",
    "kr.layers.BatchNormalization(axis=-1)\n",
    "model.add(kr.layers.Conv2D(64,kernel_size=(3, 3),activation='relu'))\n",
    "model.add(kr.layers.MaxPooling2D(pool_size=(2, 2),))\n",
    "\n",
    "model.add(kr.layers.Flatten())\n",
    "model.add(kr.layers.Dense(units=456, activation='relu'))\n",
    "kr.layers.BatchNormalization()\n",
    "model.add(kr.layers.Dropout(0.1))\n",
    "model.add(kr.layers.Dense(units=10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile model\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 9, 9, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 456)               467400    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 456)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                4570      \n",
      "=================================================================\n",
      "Total params: 536,962\n",
      "Trainable params: 536,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create image generator\n",
    "gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
    "                         height_shift_range=0.08, zoom_range=0.08)\n",
    "test_gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_generator = gen.flow(X_train, y_train, batch_size=64)\n",
    "test_generator = test_gen.flow(X_test, y_test, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\pepe\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "937/937 [==============================] - 15s 16ms/step - loss: 0.5951 - accuracy: 0.7892 - val_loss: 0.1540 - val_accuracy: 0.9698\n",
      "Epoch 2/10\n",
      "937/937 [==============================] - 13s 14ms/step - loss: 0.0762 - accuracy: 0.9730 - val_loss: 0.0220 - val_accuracy: 0.9910\n",
      "Epoch 3/10\n",
      "937/937 [==============================] - 13s 14ms/step - loss: 0.0439 - accuracy: 0.9843 - val_loss: 0.0093 - val_accuracy: 0.9922\n",
      "Epoch 4/10\n",
      "937/937 [==============================] - 13s 14ms/step - loss: 0.0327 - accuracy: 0.9884 - val_loss: 0.0189 - val_accuracy: 0.9922\n",
      "Epoch 5/10\n",
      "937/937 [==============================] - 13s 14ms/step - loss: 0.0278 - accuracy: 0.9906 - val_loss: 0.0071 - val_accuracy: 0.9904\n",
      "Epoch 6/10\n",
      "937/937 [==============================] - 13s 14ms/step - loss: 0.0204 - accuracy: 0.9930 - val_loss: 0.0228 - val_accuracy: 0.9842\n",
      "Epoch 7/10\n",
      "937/937 [==============================] - 13s 14ms/step - loss: 0.0213 - accuracy: 0.9925 - val_loss: 3.0465e-04 - val_accuracy: 0.9939\n",
      "Epoch 8/10\n",
      "937/937 [==============================] - 13s 14ms/step - loss: 0.0168 - accuracy: 0.9943 - val_loss: 0.0037 - val_accuracy: 0.9961\n",
      "Epoch 9/10\n",
      "937/937 [==============================] - 13s 14ms/step - loss: 0.0158 - accuracy: 0.9945 - val_loss: 0.0099 - val_accuracy: 0.9968\n",
      "Epoch 10/10\n",
      "937/937 [==============================] - 13s 14ms/step - loss: 0.0142 - accuracy: 0.9951 - val_loss: 8.5516e-04 - val_accuracy: 0.9986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a9d84efd88>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train 10 epoch\n",
    "epoch =10\n",
    "model.fit_generator(train_generator, steps_per_epoch=60000//64, epochs=epoch, \n",
    "                    validation_data=test_generator, validation_steps=10000//64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "937/937 [==============================] - 13s 14ms/step - loss: 0.0115 - accuracy: 0.9960 - val_loss: 3.8311e-05 - val_accuracy: 0.9953\n",
      "Epoch 2/10\n",
      "937/937 [==============================] - 13s 14ms/step - loss: 0.0128 - accuracy: 0.9959 - val_loss: 9.8865e-04 - val_accuracy: 0.9956\n",
      "Epoch 3/10\n",
      "937/937 [==============================] - 13s 14ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 5.9874e-06 - val_accuracy: 0.9954\n",
      "Epoch 4/10\n",
      "937/937 [==============================] - 13s 14ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 9.7542e-04 - val_accuracy: 0.9977\n",
      "Epoch 5/10\n",
      "937/937 [==============================] - 13s 14ms/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 1.1307e-05 - val_accuracy: 0.9985\n",
      "Epoch 6/10\n",
      "937/937 [==============================] - 13s 14ms/step - loss: 0.0096 - accuracy: 0.9970 - val_loss: 0.0028 - val_accuracy: 0.9938\n",
      "Epoch 7/10\n",
      "937/937 [==============================] - 13s 14ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 8.3186e-05 - val_accuracy: 0.9986\n",
      "Epoch 8/10\n",
      "937/937 [==============================] - 13s 14ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.0073 - val_accuracy: 0.9986\n",
      "Epoch 9/10\n",
      "937/937 [==============================] - 13s 14ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 1.3522e-04 - val_accuracy: 0.9940\n",
      "Epoch 10/10\n",
      "937/937 [==============================] - 14s 14ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.0020 - val_accuracy: 0.9968\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1ab59933908>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, steps_per_epoch=60000//64, epochs=epoch, \n",
    "                    validation_data=test_generator, validation_steps=10000//64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze function from stack overflow\n",
    "def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n",
    "    \"\"\"\n",
    "    Freezes the state of a session into a pruned computation graph.\n",
    "\n",
    "    Creates a new computation graph where variable nodes are replaced by\n",
    "    constants taking their current value in the session. The new graph will be\n",
    "    pruned so subgraphs that are not necessary to compute the requested\n",
    "    outputs are removed.\n",
    "    @param session The TensorFlow session to be frozen.\n",
    "    @param keep_var_names A list of variable names that should not be frozen,\n",
    "                          or None to freeze all the variables in the graph.\n",
    "    @param output_names Names of the relevant graph outputs.\n",
    "    @param clear_devices Remove the device directives from the graph for better portability.\n",
    "    @return The frozen graph definition.\n",
    "    \"\"\"\n",
    "    graph = session.graph\n",
    "    with graph.as_default():\n",
    "        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n",
    "        output_names = output_names or []\n",
    "        output_names += [v.op.name for v in tf.global_variables()]\n",
    "        input_graph_def = graph.as_graph_def()\n",
    "        if clear_devices:\n",
    "            for node in input_graph_def.node:\n",
    "                node.device = \"\"\n",
    "        frozen_graph = tf.graph_util.convert_variables_to_constants(\n",
    "            session, input_graph_def, output_names, freeze_var_names)\n",
    "        return frozen_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-22-af0a42548ffb>:27: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.convert_variables_to_constants\n",
      "WARNING:tensorflow:From C:\\Users\\pepe\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\graph_util_impl.py:245: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.extract_sub_graph\n",
      "INFO:tensorflow:Froze 55 variables.\n",
      "INFO:tensorflow:Converted 55 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "# froze the graph\n",
    "frozen_graph = freeze_session(K.get_session(),\n",
    "                              output_names=[out.op.name for out in model.outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../model/gesture_model.pb'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save model in file\n",
    "tf.train.write_graph(frozen_graph, \"../model/\", \"gesture_model.pb\", as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
