{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy and matplot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import keras \n",
    "import keras as kr \n",
    "# this are need for export the model al proto for be used in c#\n",
    "from keras import backend as K\n",
    "import tensorflow.compat.v1 as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image generator for argumented data\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility for split the data\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Images \n",
    "x = []\n",
    "with open(\"data/images.txt\") as f:\n",
    "    for line in f:\n",
    "      x.append(np.asarray([float(x) for x in line.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of images\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert into np and reshape\n",
    "x = np.asarray(x)\n",
    "x = x.reshape(len(x),30,30,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to float32\n",
    "x = x.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22216bd9388>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check one image\n",
    "plt.imshow(x[1554].reshape(30,30), cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load labels\n",
    "y = []\n",
    "with open(\"data/labels.txt\") as f:\n",
    "    for line in f:\n",
    "      y.append(int(line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfor labels into np array\n",
    "y = np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split labels into vectors of size 10\n",
    "y = kr.utils.to_categorical(y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into test and train\n",
    "# 33% would be the test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\pepe\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "\n",
    "model = kr.models.Sequential()\n",
    "model.add(kr.layers.Conv2D(32,kernel_size=(3, 3),activation='relu',input_shape=(30,30,1)))\n",
    "kr.layers.BatchNormalization(axis=-1)\n",
    "model.add(kr.layers.Conv2D(32,kernel_size=(3, 3),activation='relu'))\n",
    "model.add(kr.layers.MaxPooling2D(pool_size=(2, 2),))\n",
    "\n",
    "kr.layers.BatchNormalization(axis=-1)\n",
    "model.add(kr.layers.Conv2D(64,kernel_size=(3, 3),activation='relu'))\n",
    "kr.layers.BatchNormalization(axis=-1)\n",
    "model.add(kr.layers.Conv2D(64,kernel_size=(3, 3),activation='relu'))\n",
    "model.add(kr.layers.MaxPooling2D(pool_size=(2, 2),))\n",
    "\n",
    "model.add(kr.layers.Flatten())\n",
    "model.add(kr.layers.Dense(units=456, activation='relu'))\n",
    "kr.layers.BatchNormalization()\n",
    "model.add(kr.layers.Dropout(0.1))\n",
    "model.add(kr.layers.Dense(units=10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile model\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 9, 9, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 456)               467400    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 456)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                4570      \n",
      "=================================================================\n",
      "Total params: 536,962\n",
      "Trainable params: 536,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# need first and last layer name for use in c#\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create image generator\n",
    "gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
    "                         height_shift_range=0.08, zoom_range=0.08)\n",
    "test_gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 10\n",
    "history_callback = model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=epoch, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_generator = gen.flow(X_train, y_train, batch_size=64)\n",
    "test_generator = test_gen.flow(X_test, y_test, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\pepe\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "937/937 [==============================] - 17s 18ms/step - loss: 0.2311 - accuracy: 0.9221 - val_loss: 4.7592e-04 - val_accuracy: 0.9985\n",
      "Epoch 2/10\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.0172 - accuracy: 0.9946 - val_loss: 2.5333e-05 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "937/937 [==============================] - 15s 16ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 6.9205e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "937/937 [==============================] - 15s 16ms/step - loss: 0.0074 - accuracy: 0.9978 - val_loss: 6.8883e-06 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.0066 - accuracy: 0.9984 - val_loss: 1.8999e-06 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "937/937 [==============================] - 15s 16ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 6.2441e-06 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 1.4994e-07 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "937/937 [==============================] - 15s 16ms/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 2.1468e-06 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "937/937 [==============================] - 16s 17ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 1.9996e-06 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "937/937 [==============================] - 15s 16ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 1.6792e-06 - val_accuracy: 0.9985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x22217f6eb88>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train 10 epoch\n",
    "epoch =10\n",
    "model.fit_generator(train_generator, steps_per_epoch=60000//64, epochs=epoch, \n",
    "                    validation_data=test_generator, validation_steps=10000//64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(train_generator, steps_per_epoch=60000//64, epochs=epoch, \n",
    "                    validation_data=test_generator, validation_steps=10000//64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze function from stack overflow\n",
    "def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n",
    "    \"\"\"\n",
    "    Freezes the state of a session into a pruned computation graph.\n",
    "\n",
    "    Creates a new computation graph where variable nodes are replaced by\n",
    "    constants taking their current value in the session. The new graph will be\n",
    "    pruned so subgraphs that are not necessary to compute the requested\n",
    "    outputs are removed.\n",
    "    @param session The TensorFlow session to be frozen.\n",
    "    @param keep_var_names A list of variable names that should not be frozen,\n",
    "                          or None to freeze all the variables in the graph.\n",
    "    @param output_names Names of the relevant graph outputs.\n",
    "    @param clear_devices Remove the device directives from the graph for better portability.\n",
    "    @return The frozen graph definition.\n",
    "    \"\"\"\n",
    "    graph = session.graph\n",
    "    with graph.as_default():\n",
    "        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n",
    "        output_names = output_names or []\n",
    "        output_names += [v.op.name for v in tf.global_variables()]\n",
    "        input_graph_def = graph.as_graph_def()\n",
    "        if clear_devices:\n",
    "            for node in input_graph_def.node:\n",
    "                node.device = \"\"\n",
    "        frozen_graph = tf.graph_util.convert_variables_to_constants(\n",
    "            session, input_graph_def, output_names, freeze_var_names)\n",
    "        return frozen_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-20-af0a42548ffb>:27: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.convert_variables_to_constants\n",
      "WARNING:tensorflow:From C:\\Users\\pepe\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\graph_util_impl.py:245: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.extract_sub_graph\n",
      "INFO:tensorflow:Froze 55 variables.\n",
      "INFO:tensorflow:Converted 55 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "# froze the graph\n",
    "frozen_graph = freeze_session(K.get_session(),\n",
    "                              output_names=[out.op.name for out in model.outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../model/gesture_model.pb'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save model in file\n",
    "tf.train.write_graph(frozen_graph, \"../model/\", \"gesture_model.pb\", as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1,y1 = train_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.imshow(x1[9].reshape(30,30), cmap='gray')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
