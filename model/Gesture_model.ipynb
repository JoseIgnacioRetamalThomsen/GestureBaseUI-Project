{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy and matplot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import keras \n",
    "import keras as kr \n",
    "# this are need for export the model al proto for be used in c#\n",
    "from keras import backend as K\n",
    "import tensorflow.compat.v1 as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image generator for argumented data\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility for split the data\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Images \n",
    "x = []\n",
    "with open(\"data/images.txt\") as f:\n",
    "    for line in f:\n",
    "      x.append(np.asarray([float(x) for x in line.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of images\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert into np and reshape\n",
    "x = np.asarray(x)\n",
    "x = x.reshape(len(x),30,30,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to float32\n",
    "x = x.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x247bc779208>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check one image\n",
    "plt.imshow(x[1554].reshape(30,30), cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load labels\n",
    "y = []\n",
    "with open(\"data/labels.txt\") as f:\n",
    "    for line in f:\n",
    "      y.append(int(line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfor labels into np array\n",
    "y = np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split labels into vectors of size 10\n",
    "y = kr.utils.to_categorical(y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into test and train\n",
    "# 33% would be the test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\pepe\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "\n",
    "model = kr.models.Sequential()\n",
    "model.add(kr.layers.Conv2D(32,kernel_size=(3, 3),activation='relu',input_shape=(30,30,1)))\n",
    "kr.layers.BatchNormalization(axis=-1)\n",
    "model.add(kr.layers.Conv2D(32,kernel_size=(3, 3),activation='relu'))\n",
    "model.add(kr.layers.MaxPooling2D(pool_size=(2, 2),))\n",
    "\n",
    "kr.layers.BatchNormalization(axis=-1)\n",
    "model.add(kr.layers.Conv2D(64,kernel_size=(3, 3),activation='relu'))\n",
    "kr.layers.BatchNormalization(axis=-1)\n",
    "model.add(kr.layers.Conv2D(64,kernel_size=(3, 3),activation='relu'))\n",
    "model.add(kr.layers.MaxPooling2D(pool_size=(2, 2),))\n",
    "\n",
    "model.add(kr.layers.Flatten())\n",
    "model.add(kr.layers.Dense(units=456, activation='relu'))\n",
    "kr.layers.BatchNormalization()\n",
    "model.add(kr.layers.Dropout(0.1))\n",
    "model.add(kr.layers.Dense(units=10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile model\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 9, 9, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 456)               467400    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 456)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                4570      \n",
      "=================================================================\n",
      "Total params: 536,962\n",
      "Trainable params: 536,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# need first and last layer name for use in c#\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create image generator\n",
    "gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
    "                         height_shift_range=0.08, zoom_range=0.08)\n",
    "test_gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#epoch = 10\n",
    "#history_callback = model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=epoch, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_generator = gen.flow(X_train, y_train, batch_size=64)\n",
    "test_generator = test_gen.flow(X_test, y_test, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\pepe\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "937/937 [==============================] - 12s 13ms/step - loss: 0.2794 - accuracy: 0.9068 - val_loss: 0.0087 - val_accuracy: 0.9985\n",
      "Epoch 2/10\n",
      "937/937 [==============================] - 10s 11ms/step - loss: 0.0291 - accuracy: 0.9911 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "937/937 [==============================] - 10s 11ms/step - loss: 0.0188 - accuracy: 0.9938 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "937/937 [==============================] - 10s 11ms/step - loss: 0.0131 - accuracy: 0.9959 - val_loss: 8.5471e-05 - val_accuracy: 0.9984\n",
      "Epoch 5/10\n",
      "937/937 [==============================] - 10s 11ms/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 1.0086e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "937/937 [==============================] - 10s 11ms/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 4.0039e-06 - val_accuracy: 0.9979\n",
      "Epoch 7/10\n",
      "937/937 [==============================] - 10s 11ms/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 8.2632e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "937/937 [==============================] - 10s 11ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 7.9722e-07 - val_accuracy: 0.9984\n",
      "Epoch 9/10\n",
      "937/937 [==============================] - 10s 11ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 8.4467e-06 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "937/937 [==============================] - 10s 11ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.0044 - val_accuracy: 0.9993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x247c016fb88>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train 10 epoch\n",
    "epoch =10\n",
    "model.fit_generator(train_generator, steps_per_epoch=60000//64, epochs=epoch, \n",
    "                    validation_data=test_generator, validation_steps=10000//64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "937/937 [==============================] - 11s 12ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 1.3132e-07 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "937/937 [==============================] - 10s 11ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 5.5507e-07 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "937/937 [==============================] - 11s 11ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 1.5646e-07 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "937/937 [==============================] - 10s 11ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 7.8952e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "937/937 [==============================] - 11s 11ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 1.3877e-07 - val_accuracy: 0.9985\n",
      "Epoch 6/10\n",
      "937/937 [==============================] - 11s 11ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 2.4680e-07 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "937/937 [==============================] - 10s 11ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "937/937 [==============================] - 11s 11ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 5.4971e-06 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "937/937 [==============================] - 11s 11ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 8.4240e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "937/937 [==============================] - 10s 11ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 2.2483e-06 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x247c1434808>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, steps_per_epoch=60000//64, epochs=epoch, \n",
    "                    validation_data=test_generator, validation_steps=10000//64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze function from stack overflow\n",
    "def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n",
    "    \"\"\"\n",
    "    Freezes the state of a session into a pruned computation graph.\n",
    "\n",
    "    Creates a new computation graph where variable nodes are replaced by\n",
    "    constants taking their current value in the session. The new graph will be\n",
    "    pruned so subgraphs that are not necessary to compute the requested\n",
    "    outputs are removed.\n",
    "    @param session The TensorFlow session to be frozen.\n",
    "    @param keep_var_names A list of variable names that should not be frozen,\n",
    "                          or None to freeze all the variables in the graph.\n",
    "    @param output_names Names of the relevant graph outputs.\n",
    "    @param clear_devices Remove the device directives from the graph for better portability.\n",
    "    @return The frozen graph definition.\n",
    "    \"\"\"\n",
    "    graph = session.graph\n",
    "    with graph.as_default():\n",
    "        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n",
    "        output_names = output_names or []\n",
    "        output_names += [v.op.name for v in tf.global_variables()]\n",
    "        input_graph_def = graph.as_graph_def()\n",
    "        if clear_devices:\n",
    "            for node in input_graph_def.node:\n",
    "                node.device = \"\"\n",
    "        frozen_graph = tf.graph_util.convert_variables_to_constants(\n",
    "            session, input_graph_def, output_names, freeze_var_names)\n",
    "        return frozen_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-21-af0a42548ffb>:27: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.convert_variables_to_constants\n",
      "WARNING:tensorflow:From C:\\Users\\pepe\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\graph_util_impl.py:245: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.extract_sub_graph\n",
      "INFO:tensorflow:Froze 55 variables.\n",
      "INFO:tensorflow:Converted 55 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "# froze the graph\n",
    "frozen_graph = freeze_session(K.get_session(),\n",
    "                              output_names=[out.op.name for out in model.outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../model/gesture_model.pb'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save model in file\n",
    "tf.train.write_graph(frozen_graph, \"../model/\", \"gesture_model.pb\", as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1,y1 = train_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x247cef534c8>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "plt.imshow(x1[8].reshape(30,30), cmap='gray')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
