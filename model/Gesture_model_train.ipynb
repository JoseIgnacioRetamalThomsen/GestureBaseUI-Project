{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy and matplot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import keras \n",
    "import keras as kr \n",
    "# this are need for export the model al proto for be used in c#\n",
    "from keras import backend as K\n",
    "import tensorflow.compat.v1 as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image generator for argumented data\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility for split the data\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Images \n",
    "x = []\n",
    "with open(\"data/images.txt\") as f:\n",
    "    for line in f:\n",
    "      x.append(np.asarray([float(x) for x in line.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8298"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of images\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert into np and reshape\n",
    "x = np.asarray(x)\n",
    "x = x.reshape(len(x),30,30,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to float32\n",
    "x = x.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2a447066f48>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check one image\n",
    "plt.imshow(x[2250].reshape(30,30), cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load labels\n",
    "y = []\n",
    "with open(\"data/labels.txt\") as f:\n",
    "    for line in f:\n",
    "      y.append(int(line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfor labels into np array\n",
    "y = np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split labels into vectors of size 10\n",
    "y = kr.utils.to_categorical(y, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into test and train\n",
    "# 33% would be the test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\pepe\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "\n",
    "model = kr.models.Sequential()\n",
    "model.add(kr.layers.Conv2D(32,kernel_size=(3, 3),activation='relu',input_shape=(30,30,1)))\n",
    "kr.layers.BatchNormalization(axis=-1)\n",
    "model.add(kr.layers.Conv2D(32,kernel_size=(3, 3),activation='relu'))\n",
    "model.add(kr.layers.MaxPooling2D(pool_size=(2, 2),))\n",
    "\n",
    "kr.layers.BatchNormalization(axis=-1)\n",
    "model.add(kr.layers.Conv2D(64,kernel_size=(3, 3),activation='relu'))\n",
    "kr.layers.BatchNormalization(axis=-1)\n",
    "model.add(kr.layers.Conv2D(64,kernel_size=(3, 3),activation='relu'))\n",
    "model.add(kr.layers.MaxPooling2D(pool_size=(2, 2),))\n",
    "\n",
    "model.add(kr.layers.Flatten())\n",
    "model.add(kr.layers.Dense(units=456, activation='relu'))\n",
    "kr.layers.BatchNormalization()\n",
    "model.add(kr.layers.Dropout(0.1))\n",
    "model.add(kr.layers.Dense(units=13, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile model\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 9, 9, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 456)               467400    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 456)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 13)                5941      \n",
      "=================================================================\n",
      "Total params: 538,333\n",
      "Trainable params: 538,333\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# need first and last layer name for use in c#\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create image generator\n",
    "gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
    "                         height_shift_range=0.08, zoom_range=0.08)\n",
    "test_gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#epoch = 10\n",
    "#history_callback = model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=epoch, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create image generator\n",
    "train_generator = gen.flow(X_train, y_train, batch_size=64)\n",
    "test_generator = test_gen.flow(X_test, y_test, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\pepe\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "937/937 [==============================] - 14s 15ms/step - loss: 0.3436 - accuracy: 0.8877 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "937/937 [==============================] - 10s 10ms/step - loss: 0.0207 - accuracy: 0.9940 - val_loss: 0.0013 - val_accuracy: 0.9992\n",
      "Epoch 3/10\n",
      "937/937 [==============================] - 10s 10ms/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 1.5701e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "937/937 [==============================] - 10s 10ms/step - loss: 0.0077 - accuracy: 0.9975 - val_loss: 1.0979e-05 - val_accuracy: 0.9996\n",
      "Epoch 5/10\n",
      "937/937 [==============================] - 10s 11ms/step - loss: 0.0088 - accuracy: 0.9973 - val_loss: 7.1341e-05 - val_accuracy: 0.9996\n",
      "Epoch 6/10\n",
      "937/937 [==============================] - 10s 10ms/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 3.5528e-05 - val_accuracy: 0.9998\n",
      "Epoch 7/10\n",
      "937/937 [==============================] - 10s 10ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 1.5685e-04 - val_accuracy: 0.9997\n",
      "Epoch 8/10\n",
      "937/937 [==============================] - 10s 11ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 3.8577e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "937/937 [==============================] - 10s 10ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 5.1409e-07 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "937/937 [==============================] - 10s 10ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 4.0513e-07 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2a44c8ec3c8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train 10 epoch\n",
    "epoch =10\n",
    "model.fit_generator(train_generator, steps_per_epoch=60000//64, epochs=epoch, \n",
    "                    validation_data=test_generator, validation_steps=10000//64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze function from stack overflow\n",
    "def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n",
    "    \"\"\"\n",
    "    Freezes the state of a session into a pruned computation graph.\n",
    "\n",
    "    Creates a new computation graph where variable nodes are replaced by\n",
    "    constants taking their current value in the session. The new graph will be\n",
    "    pruned so subgraphs that are not necessary to compute the requested\n",
    "    outputs are removed.\n",
    "    @param session The TensorFlow session to be frozen.\n",
    "    @param keep_var_names A list of variable names that should not be frozen,\n",
    "                          or None to freeze all the variables in the graph.\n",
    "    @param output_names Names of the relevant graph outputs.\n",
    "    @param clear_devices Remove the device directives from the graph for better portability.\n",
    "    @return The frozen graph definition.\n",
    "    \"\"\"\n",
    "    graph = session.graph\n",
    "    with graph.as_default():\n",
    "        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n",
    "        output_names = output_names or []\n",
    "        output_names += [v.op.name for v in tf.global_variables()]\n",
    "        input_graph_def = graph.as_graph_def()\n",
    "        if clear_devices:\n",
    "            for node in input_graph_def.node:\n",
    "                node.device = \"\"\n",
    "        frozen_graph = tf.graph_util.convert_variables_to_constants(\n",
    "            session, input_graph_def, output_names, freeze_var_names)\n",
    "        return frozen_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-21-af0a42548ffb>:27: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.convert_variables_to_constants\n",
      "WARNING:tensorflow:From C:\\Users\\pepe\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\graph_util_impl.py:245: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.extract_sub_graph\n",
      "INFO:tensorflow:Froze 55 variables.\n",
      "INFO:tensorflow:Converted 55 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "# froze the graph\n",
    "frozen_graph = freeze_session(K.get_session(),\n",
    "                              output_names=[out.op.name for out in model.outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../model/gesture_model1.pb'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save model in file as pb importable \n",
    "tf.train.write_graph(frozen_graph, \"../model/\", \"gesture_model1.pb\", as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at some generatoed images\n",
    "x1,y1 = train_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2a5db4fad48>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "plt.imshow(x1[12].reshape(30,30), cmap='gray')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
